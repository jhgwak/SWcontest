{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6cef59-f25f-4500-8b16-30e14c09aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "630194ed-3b6a-429c-99f8-5b4440fab521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow.keras.layers as tl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split # LSTM을 사용할 것이라 딱히 필요없을 것으로 보임\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, MaxAbsScaler # Scipy에 제시된 대표적인 스케일링 기법\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c98e4-3405-4f7e-a7eb-2c2e6275ff5f",
   "metadata": {},
   "source": [
    "### 영상 데이터를 프레임별로 쪼개는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6486c1-6faa-4074-9d5f-8e00e8c7e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 360\n",
    "HEIGHT = 540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec974a14-3a57-47bf-87e6-60322148c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path: /Users/ichanho/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print(\"current path:\",path)\n",
    "hoon_video_path = path + \"/test3.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b03532f-bb0b-4cc8-8435-c8141a0f5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoon_file_list = glob(hoon_video_path, recursive=True)\n",
    "hoon_file_list = hoon_file_list[1:]\n",
    "hoon_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dff5a62-b66f-4c31-8d83-bcd440c1da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: hoon_images: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir hoon_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234814d7-cc7b-4f3b-a864-c802c5225ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf hoon_images/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "139b656f-7ebf-417e-b700-6f55a4f3ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(hoon_video_path)\n",
    "frame_count = 0\n",
    "status, image = cap.read()\n",
    "image = cv2.flip(image, 0)\n",
    "image = cv2.flip(image, 1)\n",
    "while(status):\n",
    "    cv2.imwrite(\"./hoon_images/input_%05d.jpg\"%frame_count, image)\n",
    "    status, image = cap.read()\n",
    "    image = cv2.flip(image, 0)\n",
    "    frame_count = frame_count +1\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a424d66-8b14-4090-b785-d5e229ca4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf converted_image/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d920cffd-456f-4a2c-8400-0c6e3ad56139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints(frame, proto_file, weights_file, threshold, model_name, BODY_PARTS):\n",
    "    global points\n",
    "\n",
    "    # 네트워크 불러오기\n",
    "    net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
    "\n",
    "    # 입력 이미지의 사이즈 정의\n",
    "    image_height = HEIGHT\n",
    "    image_width = WIDTH\n",
    "\n",
    "    # 네트워크에 넣기 위한 전처리\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (image_width, image_height), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # 전처리된 blob 네트워크에 입력\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    out = net.forward()\n",
    "    # The output is a 4D matrix :\n",
    "    # The first dimension being the image ID ( in case you pass more than one image to the network ).\n",
    "    # The second dimension indicates the index of a keypoint.\n",
    "    # The model produces Confidence Maps and Part Affinity maps which are all concatenated.\n",
    "    # For COCO model it consists of 57 parts – 18 keypoint confidence Maps + 1 background + 19*2 Part Affinity Maps. Similarly, for MPI, it produces 44 points.\n",
    "    # We will be using only the first few points which correspond to Keypoints.\n",
    "    # The third dimension is the height of the output map.\n",
    "    out_height = out.shape[2]\n",
    "    # The fourth dimension is the width of the output map.\n",
    "    out_width = out.shape[3]\n",
    "\n",
    "    # 원본 이미지의 높이, 너비를 받아오기\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # 포인트 리스트 초기화\n",
    "    points = []\n",
    "\n",
    "    # print(f\"\\n============================== {model_name} Model ==============================\")\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        if((i>=0)and(i<=7)):\n",
    "            continue\n",
    "        if(i==25):\n",
    "            continue\n",
    "        if((i>=15)and(i<=18)):\n",
    "            continue\n",
    "        \n",
    "        # 신체 부위의 confidence map\n",
    "        prob_map = out[0, i, :, :]\n",
    "\n",
    "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
    "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
    "\n",
    "        # 원본 이미지에 맞게 포인트 위치 조정\n",
    "        x = (frame_width * point[0]) / out_width\n",
    "        x = int(x)\n",
    "        y = (frame_height * point[1]) / out_height\n",
    "        y = int(y)\n",
    "\n",
    "        if prob > threshold:  # [pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append((x, y))\n",
    "            # print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "        else:  # [not pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(None)\n",
    "            # print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "    #cv2_imshow(\"Output_Keypoints\", frame)\n",
    "    #cv2.imshow(\"Walking Vision Test\", frame)\n",
    "    #cv2.waitKey(10)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ea0a976-558b-46b2-abe1-67a86c997a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_and_image(frame, proto_file, weights_file, threshold, model_name, BODY_PARTS):\n",
    "    global points\n",
    "\n",
    "    # 네트워크 불러오기\n",
    "    net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
    "\n",
    "    # 입력 이미지의 사이즈 정의\n",
    "    image_height = HEIGHT\n",
    "    image_width = WIDTH\n",
    "\n",
    "    # 네트워크에 넣기 위한 전처리\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (image_width, image_height), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # 전처리된 blob 네트워크에 입력\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    out = net.forward()\n",
    "    out_height = out.shape[2]\n",
    "    out_width = out.shape[3]\n",
    "\n",
    "    # 원본 이미지의 높이, 너비를 받아오기\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # 포인트 리스트 초기화\n",
    "    points = []\n",
    "\n",
    "    # print(f\"\\n============================== {model_name} Model ==============================\")\n",
    "    \n",
    "    ###############################################################################################\n",
    "    # Making The CSV File\n",
    "    # 1. make the columns\n",
    "    # 2. input the data\n",
    "    # \n",
    "\n",
    "    \n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        if((i>=0)and(i<=7)):\n",
    "            continue\n",
    "        if(i==25):\n",
    "            continue\n",
    "        if((i>=15)and(i<=18)):\n",
    "            continue\n",
    "        \n",
    "        # 신체 부위의 confidence map\n",
    "        prob_map = out[0, i, :, :]\n",
    "\n",
    "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
    "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
    "\n",
    "        # 원본 이미지에 맞게 포인트 위치 조정\n",
    "        x = (frame_width * point[0]) / out_width\n",
    "        x = int(x)\n",
    "        y = (frame_height * point[1]) / out_height\n",
    "        y = int(y)\n",
    "        #if(i==10):\n",
    "        #    print(\"RKnee:\", (x, y))\n",
    "        #if(i==13):\n",
    "        #    print(\"LKnee:\", (x, y))\n",
    "        if((i>=0)and(i<=7)):\n",
    "            continue\n",
    "        if(i==25):\n",
    "            continue\n",
    "        if((i>=15)and(i<=18)):\n",
    "            continue\n",
    "\n",
    "        if prob > threshold:  # [pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(x)\n",
    "            points.append(y)\n",
    "            #print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "        else:  # [not pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(x)\n",
    "            points.append(y)\n",
    "            #points.append(None)\n",
    "            #print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "    #np_list = np.array(points)\n",
    "    #cv2_imshow(\"Output_Keypoints\", frame)\n",
    "    #cv2.imshow(\"Walking Vision Test\", frame)\n",
    "    #cv2.waitKey(10)\n",
    "    \n",
    "    return frame, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37fcd937-1cab-4937-9590-76c9d0a6fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints_with_lines(frame, POSE_PAIRS):\n",
    "    print()\n",
    "    for pair in POSE_PAIRS:\n",
    "        print(pair)\n",
    "        part_a = pair[0]  # 0 (Head)\n",
    "        part_b = pair[1]  # 1 (Neck)\n",
    "        if points[part_a] and points[part_b]:\n",
    "            print(f\"[linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "            cv2.line(frame, points[part_a], points[part_b], (0, 255, 0), 3)\n",
    "        else:\n",
    "            print(f\"[not linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "\n",
    "    #cv2_imshow(\"output_keypoints_with_lines\", frame)\n",
    "    cv2.imshow(\"walking vision\", frame)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d544312f-33b5-44f6-a526-fe2561806cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS_BODY_25 = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                      5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"MidHip\", 9: \"RHip\",\n",
    "                      10: \"RKnee\", 11: \"RAnkle\", 12: \"LHip\", 13: \"LKnee\", 14: \"LAnkle\",\n",
    "                      15: \"REye\", 16: \"LEye\", 17: \"REar\", 18: \"LEar\", 19: \"LBigToe\",\n",
    "                      20: \"LSmallToe\", 21: \"LHeel\", 22: \"RBigToe\", 23: \"RSmallToe\", 24: \"RHeel\", 25: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_BODY_25 = [[0, 1], [0, 15], [0, 16], [1, 2], [1, 5], [1, 8], [8, 9], [8, 12], [9, 10], [12, 13], [2, 3],\n",
    "                      [3, 4], [5, 6], [6, 7], [10, 11], [13, 14], [15, 17], [16, 18], [14, 21], [19, 21], [20, 21],\n",
    "                      [11, 24], [22, 24], [23, 24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b849123e-3206-4094-a018-98c5be6ee6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: converted_image: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 947/947 [23:37<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "protoFile_body_25 = \"./openpose/models/pose/body_25/pose_deploy.prototxt\"\n",
    "weightsFile_body_25 = \"./openpose/models/pose/body_25/pose_iter_584000.caffemodel\"\n",
    "\n",
    "# 이미지 경로\n",
    "!mkdir converted_image\n",
    "hoon_file_list = glob(\"./hoon_images/**.jpg\", recursive=True)\n",
    "hoon_file_list.sort()\n",
    "# print(hoon_file_list[0][14:])\n",
    "convert_path = \"./converted_image/\"\n",
    "file = open(\"./data.csv\", 'w', newline='')\n",
    "wr = csv.writer(file)\n",
    "for i in tqdm(hoon_file_list):\n",
    "    man = i\n",
    "    name = convert_path + i[14:]\n",
    "    # 키포인트를 저장할 빈 리스트\n",
    "    points = []\n",
    "\n",
    "    # 이미지 읽어오기\n",
    "    frame_mpii = cv2.imread(man)\n",
    "    frame_body_25 = frame_mpii.copy()\n",
    "\n",
    "    frame_BODY_25, info = make_csv_and_image(frame=frame_body_25, proto_file=protoFile_body_25, weights_file=weightsFile_body_25,threshold=0.2, model_name=\"BODY_25\", BODY_PARTS=BODY_PARTS_BODY_25)\n",
    "    del(info[15:19])\n",
    "    del(info[0:8])\n",
    "    del(info[-1])\n",
    "    cv2.imwrite(name, frame_BODY_25)\n",
    "    wr.writerow(info)\n",
    "file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5da17d32-b124-4b5d-9726-95458aaf6cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(939, 13)\n"
     ]
    }
   ],
   "source": [
    "input_data = open(\"./data.csv\", 'r')\n",
    "read = csv.reader(input_data)\n",
    "mydata = []\n",
    "\n",
    "cnt = 0\n",
    "for i in read:\n",
    "    if(cnt == 0):\n",
    "        cnt += 1\n",
    "        continue\n",
    "    if(cnt >= 940):\n",
    "        cnt += 1\n",
    "        continue\n",
    "    \n",
    "    mydata.append(i)\n",
    "    cnt += 1\n",
    "\n",
    "input_data.close()\n",
    "train = np.array(mydata)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e1f4c-1442-43c8-93d6-3b9feaab855a",
   "metadata": {},
   "source": [
    "### 프레임 별로 쪼갠 데이터를 Sequence화 하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2a892f16-ae08-46dd-b35c-9c23ec9000a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3dace415-73c2-43a7-a20e-12bceff28a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequence(args):\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(args) - seq_length):\n",
    "        full_seq_data.append(args[seq:seq + seq_length])\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    return full_seq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "600f0f6d-fbcf-4217-a939-cdce630487f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(879, 60, 13)\n"
     ]
    }
   ],
   "source": [
    "train_x = Sequence(train)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f466bc3b-73c6-4407-ba7a-869c47f2be35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = []\n",
    "ans = 1\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "    train_y.append(ans)\n",
    "train_y = np.array(train_y)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f7110-28c5-44e8-89f9-6358d9fae8b5",
   "metadata": {},
   "source": [
    "### 모델 생성 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "69cc6b1f-9e03-46f7-8599-13edc3e6ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "000b0ded-b402-4fec-bbb5-5d13a534686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tl.LSTM(64, return_sequences = True, activation='softmax', input_shape = train_x.shape[1:]))\n",
    "model.add(tl.Dropout(0.2))\n",
    "model.add(tl.Dense(100, activation = None))\n",
    "model.add(tl.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9e7054b2-5ca6-4dc6-be6c-178594c04c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 60, 64)            19968     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60, 64)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 60, 100)           6500      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 60, 3)             303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,771\n",
      "Trainable params: 26,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'Adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1ccd2b7a-dd20-4154-ba13-e06ed7ab31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d37353fd-4892-4c60-99f1-9eda5eb6c73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sequential_2/Cast\n (defined at /opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py:671)\n]] [Op:__inference_train_function_6279]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/Cast:\nIn[0] IteratorGetNext (defined at /opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py:866)\n\nOperation defined at: (most recent call last)\n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-151-bf1bb848ae9a>\", line 1, in <cell line: 1>\n>>>     model.fit(train_x, train_y, epochs=50, callbacks=early_stopping)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py\", line 571, in _run_internal_graph\n>>>     y = self._conform_to_reference_input(y, ref_input=x)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py\", line 671, in _conform_to_reference_input\n>>>     tensor = tf.cast(tensor, dtype=ref_input.dtype)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [151]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sequential_2/Cast\n (defined at /opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py:671)\n]] [Op:__inference_train_function_6279]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/Cast:\nIn[0] IteratorGetNext (defined at /opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py:866)\n\nOperation defined at: (most recent call last)\n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-151-bf1bb848ae9a>\", line 1, in <cell line: 1>\n>>>     model.fit(train_x, train_y, epochs=50, callbacks=early_stopping)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py\", line 571, in _run_internal_graph\n>>>     y = self._conform_to_reference_input(y, ref_input=x)\n>>> \n>>>   File \"/opt/anaconda3/envs/openpose/lib/python3.8/site-packages/keras/engine/functional.py\", line 671, in _conform_to_reference_input\n>>>     tensor = tf.cast(tensor, dtype=ref_input.dtype)\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=50, callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb37a1e-0d67-46c1-b2b1-7a79b87779a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
